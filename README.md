# event-representation-processing

* Code for various methods to convert event-based camera data into RGB-like representations.
* This repository integrates various event representation methods from multiple research papers, refining and modifying them to provide a simple, intuitive, and user-friendly Python conversion tool.
* During the integration process, the original source code and algorithms are preserved as much as possible to ensure their effectiveness.
* This is the script for converting the DailyDVS200 dataset -> [DailyDVS200_dataset_use](DailyDVS200_dataset_use)
---
* é€™å€‹ repo æ•´åˆäº†å¤šç¯‡è«–æ–‡ä¸­çš„ Event Representation æ–¹æ³•ï¼Œä¸¦é€²è¡Œæ”¹é€²èˆ‡èª¿æ•´ï¼Œæ—¨åœ¨æä¾›ä¸€å€‹ç°¡å–®ã€ç›´è§€ä¸”æ˜“æ–¼ä½¿ç”¨çš„ Python è½‰æ›å·¥å…·ã€‚
* æ•´åˆéç¨‹ä¸­ï¼Œç›¡é‡ä¿ç•™ä¾†æºåŸå§‹ç¢¼èˆ‡æ¼”ç®—æ³•ï¼Œä»¥ç¢ºä¿å…¶æœ‰æ•ˆæ€§
* é€™è£¡é †ä¾¿é™„ä¸Šdataset DailyDVS200 è½‰æ›ç”¨çš„è…³æœ¬ -> [DailyDVS200_dataset_use](DailyDVS200_dataset_use)
---

## ğŸš€ Quick Start Guide

#### ğŸ—ï¸ 1. Install Dependencies
```sh
conda create -n event_representation python=3.10
conda activate event_representation
pip install -r requirements.txt
```

#### ğŸ”„ 2. Convert Event Data

```python
from EventProcessing import EventFrameConverter

# Other representation converter
# from EventProcessing import EventCountConverter
# from EventProcessing import EventTimeSurfaceConverter
# from EventProcessing import EventSpeedInvariantTimeSurfaceConverter
# from EventProcessing import EventAFEConverter
# from EventProcessing import EventGTEConverter
# from EventProcessing import EventVoxelGridConverter

in_path = "./event_stream.aedat4"
output_path = "./output_event_representation_dir"

# width, height: event camera resolution
# interval: Controls how many time event data to be merged, in seconds, Some representations do not require this parameter
converter = EventFrameConverter(width=320, height=240, interval=0.5)
converter.events_to_event_images(input_filepath=in_path, output_file_dir=output_path)
```

## ğŸ“š Current representation

### ğŸ“Œ Event Frame

* Method reference: Unknown
* Published in: Unknown
* Code reference: https://github.com/QiWang233/DailyDVS-200/blob/main/utils/event_image_convert.py

| Hyperparameter | Default Value | Default Value Source |
|----------------|---------------|----------------------|
| Interval       | 0.5           | Paper: DailyDVS-200  |

![00000002.png](src%2Ffigs%2FEventFrameConverter%2F00000002.png)
![00000003.png](src%2Ffigs%2FEventFrameConverter%2F00000003.png)
![00000004.png](src%2Ffigs%2FEventFrameConverter%2F00000004.png)
![00000005.png](src%2Ffigs%2FEventFrameConverter%2F00000005.png)


### ğŸ“Œ Event Count (Event Histogram, Event Count Histogram)

* Method reference: Event-based vision meets deep learning on steering prediction for self-driving cars
* Published in: CVPR 2018
* Code reference: https://dv-processing.inivation.com/rel_1_7/accumulators.html

| Hyperparameter | Default Value | Default Value Source |
|----------------|---------------|----------------------|
| Interval       | 0.5           | NO                   |

![00000002.png](src%2Ffigs%2FEventCountConverter%2F00000002.png)
![00000003.png](src%2Ffigs%2FEventCountConverter%2F00000003.png)
![00000004.png](src%2Ffigs%2FEventCountConverter%2F00000004.png)
![00000005.png](src%2Ffigs%2FEventCountConverter%2F00000005.png)

### ğŸ“Œ Time Surface

* Method reference: Event-based visual flow
* Published in: IEEE Transactions on Neural Networks and Learning Systems 2014
* Code reference: https://dv-processing.inivation.com/rel_1_7/accumulators.html

| Hyperparameter | Default Value | Default Value Source |
|----------------|---------------|----------------------|
| Interval       | 0.5           | NO                   |

> This example event stream appears less distinct in the time surface representation series due to the high density of event data. However, a slight gradient can still be observed in the first image.

![00000002.png](src%2Ffigs%2FEventTimeSurfaceConverter%2F00000002.png)
![00000003.png](src%2Ffigs%2FEventTimeSurfaceConverter%2F00000003.png)
![00000004.png](src%2Ffigs%2FEventTimeSurfaceConverter%2F00000004.png)
![00000005.png](src%2Ffigs%2FEventTimeSurfaceConverter%2F00000005.png)

### ğŸ“Œ Speed Invariant Time Surface

* Method reference: Speed invariant time surface for learning to detect corner points with event-based cameras
* Published in: CVPR 2019
* Code reference: https://dv-processing.inivation.com/rel_1_7/accumulators.html

| Hyperparameter | Default Value | Default Value Source |
|----------------|---------------|----------------------|
| Interval       | 0.5           | NO                   |

![00000002.png](src%2Ffigs%2FEventSpeedInvariantTimeSurfaceConverter%2F00000002.png)
![00000003.png](src%2Ffigs%2FEventSpeedInvariantTimeSurfaceConverter%2F00000003.png)
![00000004.png](src%2Ffigs%2FEventSpeedInvariantTimeSurfaceConverter%2F00000004.png)
![00000005.png](src%2Ffigs%2FEventSpeedInvariantTimeSurfaceConverter%2F00000005.png)

### ğŸ“Œ Adaptive Fine-grained Event (AFE)

* Method reference: ExACT: Language-guided Conceptual Reasoning and Uncertainty Estimation for Event-based Action
  Recognition and More
* Published in: CVPR 2024
* Code reference: https://github.com/jiazhou-garland/ExACT.git

> The author mentioned that the hyperparameter of this method must be readjusted according to each dataset

| Hyperparameter         | Default Value | Default Value Source    |
|------------------------|---------------|-------------------------|
| sample_event_threshold | 40            | From the original paper |
| sample_event_num_min   | 100000        | From the original paper |

![00000015.png](src%2Ffigs%2FEventAFEConverter%2F00000015.png)
![00000016.png](src%2Ffigs%2FEventAFEConverter%2F00000016.png)
![00000017.png](src%2Ffigs%2FEventAFEConverter%2F00000017.png)
![00000018.png](src%2Ffigs%2FEventAFEConverter%2F00000018.png)

### ğŸ“Œ Voxel Grid

* Method reference: Unsupervised event-based learning of optical flow, depth and egomotion.
* Published in: CVPRW 2019
* Code reference:  https://github.com/Peterande/GET-Group-Event-Transformer/blob/master/event_based/voxel_grid.py

| Hyperparameter | Default Value | Default Value Source    |
|----------------|---------------|-------------------------|
| voxel_bin_num  | 9             | From the original paper |

> The image appears to have nothing, but it's actually just too dark. You can refer to the plot below, which shows the pixel value distribution of the VoxelGrid image.  
> Because the image is barely visible, an additional .npy file has been saved for direct usage.  
> npy shape: [voxel_bin_num, height, width]  
> ![VoxelGrid image pixel value distribution.png](src%2FVoxelGrid%20image%20pixel%20value%20distribution.png)  
> Y-axis: Image pixel value  
> X-axis: Image pixel index  

![00000004.png](src%2Ffigs%2FEventVoxelGridConverter%2F00000004.png)
![00000005.png](src%2Ffigs%2FEventVoxelGridConverter%2F00000005.png)
![00000006.png](src%2Ffigs%2FEventVoxelGridConverter%2F00000006.png)
![00000007.png](src%2Ffigs%2FEventVoxelGridConverter%2F00000007.png)

### ğŸ“Œ Group Token Embedding (GTE)

* Method reference: GET: Group Event Transformer for Event-Based Vision
* Published in: ICCV 2023
* Code reference:
    * https://github.com/Peterande/GET-Group-Event-Transformer/blob/master/event_based/event_token.py
    * https://github.com/QiWang233/DailyDVS-200/blob/main/models/GET/event_based/event_token.py

> Since the number of channels is 4, it cannot be converted into an image. Therefore, it is saved as an `.npy` file with the shape:  
> `[channel, H // patch_size, W // patch_size]`
>
> In the original repository, the event stream undergoes [random augmentation](https://github.com/Peterande/GET-Group-Event-Transformer/blob/d979d7a243201d4c86cd1765636b167d7701d881/data/build.py#L182).  
> However, this repository does not apply the same augmentation due to the following reasons:
>
> * **Comparability**: Ensuring that all representations share the same training dataset conditions, reducing experimental errors.
> * **Efficiency**: Using the author's augmentation method prevents dataset preprocessing, requiring augmentation to be applied during training, which increases processing time.


> å› é€šé“æ•¸æ˜¯4ç„¡æ³•è½‰æˆåœ–ç‰‡ï¼Œå› æ­¤è¼¸å‡ºæˆnpyï¼Œnpy shape: `[channel, H // patch_size, W // patch_size]`
> 
> åœ¨åŸå§‹repoå…§ï¼Œä»–æœ‰å°event streamé€²è¡Œ[random augmentation](https://github.com/Peterande/GET-Group-Event-Transformer/blob/d979d7a243201d4c86cd1765636b167d7701d881/data/build.py#L182)ï¼Œä½†å› ç‚ºä»¥ä¸‹åŸå› ï¼Œæœ¬repoæ²’é€™éº¼åš  
>* **å¯æ¯”æ€§**: ä½¿æ‰€æœ‰representationæ“æœ‰åŒä¸€å€‹training datasetæ¢ä»¶ï¼Œé™ä½å¯¦é©—èª¤å·®  
>* **æ•ˆç‡**: è‹¥ä½¿ç”¨ä½œè€…æä¾›çš„augmentationï¼Œè³‡æ–™é›†ç„¡æ³•é å…ˆè™•ç†ï¼Œé€™æ¨£å°±å¿…é ˆåœ¨trainingéç¨‹ä¸­èŠ±æ™‚é–“è™•ç†  

| Hyperparameter | Default Value | Default Value Source    |
|----------------|---------------|-------------------------|
| patch_size     | (4, 4)        | From the original paper |
| group_num      | 12            | From the original paper |
